{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification\n",
    "\n",
    "- Pandas Documentation: http://pandas.pydata.org/\n",
    "- Scikit Learn Documentation: http://scikit-learn.org/stable/documentation.html\n",
    "- Seaborn Documentation: http://seaborn.pydata.org/\n",
    "- Keras Documentation: https://keras.io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification\n",
    "\n",
    "Our goal is to perform a binary classification on text data. We will perform both a Spam detection example and a Sentiment analysis example. We will attemp 3 strategies:\n",
    "\n",
    "1) build naive features based on our ideas\n",
    "2) use well tested feature extraction technique\n",
    "3) use deep learning and recurrent models on text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Spam detection on SMS messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/sms.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise1: Encode Labels to 0 and 1\n",
    "\n",
    "Create a variable called y that contains 0 for HAM messages and 1 for SPAM messages. There are several ways to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Build naive features based on keywords\n",
    "\n",
    "- turn all your sms messages to lowercase\n",
    "- define a function to count occurrences of a keyword with the following signature:\n",
    "\n",
    "        def count_word(word, sentence):\n",
    "            ....\n",
    "            return count_word_in_sentence\n",
    "\n",
    "- create a feature matrix `X` using counts of some keywords of your choice\n",
    "- create other similar features. You could use:\n",
    "    - the length of the message\n",
    "    - the presence of numbers\n",
    "    - the presence of special characters\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Train first model and evaluate performance\n",
    "\n",
    "- split data in train and test with `test_size=0.3, random_state=0`\n",
    "- train model of your choice on these features\n",
    "- evaluate performance on training and test set\n",
    "- discuss with classmate:\n",
    "    - is model overfitting?\n",
    "    - is model better than benchmark?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Cross Validation\n",
    "\n",
    "- perform a 5-Fold cross validation on your model\n",
    "- print the confusion matrix and the classification report on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Count Features\n",
    "\n",
    "- use features based on word counts using the `CountVectorizer` class from Scikit Learn\n",
    "- encapsulate model training and evaluation in a function\n",
    "- did you improve the performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "The previous dataset was easy. Let's switch to a harder one and do sentiment analysis on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/rt_critics.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fresh'].value_counts() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.fresh != 'none'].copy()\n",
    "df['fresh'].value_counts() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = le.fit_transform(df['fresh'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: TFIDF\n",
    "\n",
    "- Build features with word frequencies (Tfidf)\n",
    "- do train/test split\n",
    "- train and evaluate a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7: NLP with deep learning\n",
    "\n",
    "- Use the Tokenizer from Keras to:\n",
    "    - Create a vocabolary\n",
    "    - Convert sentences to sequences of integers\n",
    "- pad the sequences so that they look like a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Train / Test split on sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8: Build recurrent neural network model\n",
    "- use what you have learned to build a recurrent model that classifies the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9\n",
    "\n",
    "- Try changing the network architecture and re-train the model at each change. Can you avoid overfitting?\n",
    "    - change the number of nodes in the LSTM layer\n",
    "    - change the output dimension of the Embedding layer\n",
    "    - add dropout and recurrent dropout to the LSTM\n",
    "    - add a second LSTM layer\n",
    "    - add kernel regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "copyright": true
   },
   "source": [
    "*Copyright &copy; 2017 Francesco Mosconi & CATALIT LLC. All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
