{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Keras to Tensorflow & Transfer Learning\n",
    "\n",
    "Adapted from: https://github.com/Tony607/Keras_catVSdog_tf_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "assert \"1.4\" <= tf.__version__, \"TensorFlow r1.4 or later is needed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cats_dir = '../data/catsdogs/train/cats'\n",
    "train_dogs_dir = '../data/catsdogs/train/dogs'\n",
    "test_cats_dir = '../data/catsdogs/test/cats'\n",
    "test_dogs_dir = '../data/catsdogs/test/dogs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
    "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
    "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
    "print('total test dog images:', len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_full_path(folder):\n",
    "    return [os.path.join(folder, file_name) for file_name in os.listdir(folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shuffle_dataset(cats_dir, dogs_dir):\n",
    "    CAT_LABEL = 0\n",
    "    DOG_LABEL = 1\n",
    "    \n",
    "    cats = create_full_path(cats_dir)\n",
    "    dogs = create_full_path(dogs_dir)\n",
    "    \n",
    "    files = cats + dogs\n",
    "    labels = [CAT_LABEL] * len(cats) + [DOG_LABEL] * len(dogs)\n",
    "    return unison_shuffled_copies(files, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, train_labels = create_shuffle_dataset(train_cats_dir, train_dogs_dir)\n",
    "test_files, test_labels = create_shuffle_dataset(test_cats_dir, test_dogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_files[:10])\n",
    "print(train_labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a list of files in input and a list of labels in output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Keras model\n",
    "We are leveraging the pre-trained VGG16 model's convolution layers. aka the \"convolutional base\" of the model. Then we add our own classifier fully connected layers to do binary classification(cat vs dog). \n",
    "\n",
    "Note that since we don't want to touch the parameters pre-trained in the \"convolutional base\", so we set them as not trainable. Want to go deeper how this model works? Check out this great [jupyter notebook](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.3-using-a-pretrained-convnet.ipynb) by the creator of Keras.\n",
    "\n",
    "Use keras from tensorflow  `tensorflow.python.keras`. This is new in tensorflow version 1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten\n",
    "from tensorflow.python.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Complete the keras model so that is thas the correct output for a binary classification.\n",
    "\n",
    "Make sure to check the shape of the output of `conv_base` and plan your layers accordingly.\n",
    "\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "\n",
    "... your code here\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Freeze all the layers in conv_base, so that it's not trainable. After this the `model.summary` should look like:\n",
    "\n",
    "    _________________________________________________________________\n",
    "    Layer (type)                 Output Shape              Param #   \n",
    "    =================================================================\n",
    "    vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
    "    _________________________________________________________________\n",
    "    flatten_1 (Flatten)          (None, 8192)              0         \n",
    "    _________________________________________________________________\n",
    "    dense_1 (Dense)              (None, 256)               2097408   \n",
    "    _________________________________________________________________\n",
    "    dense_2 (Dense)              (None, 1)                 257       \n",
    "    =================================================================\n",
    "    Total params: 16,812,353\n",
    "    Trainable params: 2,097,665\n",
    "    Non-trainable params: 14,714,688\n",
    "    _________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=2e-5),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model to TF Estimator\n",
    "\n",
    "`model_dir` will be our location to store trained tensorflow models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join(os.getcwd(), \"../models/catvsdog\")\n",
    "if os.path.exists(model_dir):\n",
    "    shutil.rmtree(model_dir)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "print(\"model_dir: \",model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.estimator import model_to_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_estimator = model_to_estimator(keras_model=model, model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input_name is the model's input layer name, we will need it later when building Input function for your estimator. More on that in Input function section below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = model.input_names[0]\n",
    "input_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input function\n",
    "When we train our model, we'll need a function that reads the input image files/labels and returns the image data and labels. Estimators require that you create a function of the following format:\n",
    "````\n",
    "def input_fn():\n",
    "    ...<code>...\n",
    "    return ({ 'input_1':[ImagesValues]},\n",
    "            [ImageTypeLogit])\n",
    "```\n",
    "The return value must be a two-element tuple organized as follows: :\n",
    "\n",
    "- The first element must be a dictionary in which each input feature is a key, and then a list of values for the training batch.\n",
    "- The second element is a list of labels for the training batch.\n",
    "### Arguments\n",
    "- **filenames**, an array of image file names\n",
    "- **labels=None**, an array of the image labels for the model. Set to None for inference\n",
    "- **perform_shuffle=False**, useful when training, reads batch_size records, then shuffles (randomizes) their order.\n",
    "- **repeat_count=1**, useful when training, repeat the input data several times for each epoch\n",
    "- **batch_size=1**, reads batch_size records at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "\n",
    "Let's complete the function below by adding the following steps at the end:\n",
    "\n",
    "1. map the `_parse_function` onto the dataset\n",
    "- perform the shuffle if `perform_shuffle` is `True`\n",
    "- repeat the dataset if there's more than one epoch\n",
    "- set the batch size\n",
    "- set the iterator\n",
    "- return the next batch of features and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def imgs_input_fn(filenames, labels=None, perform_shuffle=False, repeat_count=1, batch_size=1):\n",
    "    \n",
    "    def _parse_function(filename, label):\n",
    "        image_string = tf.read_file(filename)\n",
    "        image = tf.image.decode_image(image_string, channels=3)\n",
    "        image.set_shape([None, None, None])\n",
    "        image = tf.image.resize_images(image, [150, 150])\n",
    "        image = tf.subtract(image, 116.779) # Zero-center by mean pixel\n",
    "        image.set_shape([150, 150, 3])\n",
    "        image = tf.reverse(image, axis=[2]) # 'RGB'->'BGR'\n",
    "        d = dict(zip([input_name], [image])), label\n",
    "        return d\n",
    "    \n",
    "    if labels is None:\n",
    "        labels = [0]*len(filenames)\n",
    "    \n",
    "    labels=np.array(labels)\n",
    "    \n",
    "    # Expand the shape of \"labels\" if necessory\n",
    "    if len(labels.shape) == 1:\n",
    "        labels = np.expand_dims(labels, axis=1)\n",
    "    \n",
    "    filenames = tf.constant(filenames)\n",
    "    labels = tf.constant(labels)\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "\n",
    "    .... your code here\n",
    "    \n",
    "    return batch_features, batch_labels\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the input function output\n",
    "Looks like color channels 'RGB' has changed to 'BGR' and shape resized to (150, 150) correctly for our model. That is the input format the VGG16's \"convolutional base\" is expecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_batch = imgs_input_fn(test_files, labels=test_labels, perform_shuffle=True, batch_size=20)\n",
    "with tf.Session() as sess:\n",
    "    first_batch = sess.run(next_batch)\n",
    "x_d = first_batch[0]['vgg16_input']\n",
    "\n",
    "print(x_d.shape)\n",
    "img = image.array_to_img(x_d[8])\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "Estimators require an `input_fn` with no arguments, so we create a function with no arguments using lambda. Suggested you should only attempt it if you have access to a GPU, it only takes couple minutes. Stop training after \"repeat_count\" iterations of train data (epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_estimator.train(\n",
    "    input_fn=lambda: imgs_input_fn(test_files,\n",
    "                                   labels=test_labels,\n",
    "                                   perform_shuffle=True,\n",
    "                                   repeat_count=5,\n",
    "                                   batch_size=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "Evaluate our model using the examples contained in test_files and test_labels\n",
    "\n",
    "Return value will contain evaluation_metrics such as: loss & average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_results = tf_estimator.evaluate(\n",
    "    input_fn=lambda: imgs_input_fn(test_files, \n",
    "                                   labels=test_labels, \n",
    "                                   perform_shuffle=False,\n",
    "                                   batch_size=1))\n",
    "print(\"Evaluation results\")\n",
    "for key in evaluate_results:\n",
    "    print(\"   {}, was: {}\".format(key, evaluate_results[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "To predict we can set the `labels` to None because that is what we will be predicting.\n",
    "\n",
    "Here we only predict the first 10 images in the test_files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_results = tf_estimator.predict(\n",
    "    input_fn=lambda: imgs_input_fn(test_files[:10], \n",
    "                                   labels=None, \n",
    "                                   perform_shuffle=False,\n",
    "                                   batch_size=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_logits = []\n",
    "for prediction in predict_results:\n",
    "    predict_logits.append(prediction['dense_2'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the prediction result\n",
    "The model correctly classified all 10 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_is_dog = [logit > 0.5 for logit in predict_logits]\n",
    "actual_is_dog = [label > 0.5 for label in test_labels[:10]]\n",
    "print(\"Predict dog:\",predict_is_dog)\n",
    "print(\"Actual dog :\",actual_is_dog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.estimator.train_and_evaluate\n",
    "\n",
    "TensorFlow release 1.4 also introduces the utility function **tf.estimator.train_and_evaluate**, which simplifies training, evaluation, and exporting Estimator models. This function enables distributed execution for training and evaluation, while still supporting local execution.\n",
    "\n",
    "Notice that the train was build on previous training result when we call the `est_catvsdog.train()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spec = tf.estimator.TrainSpec(input_fn=lambda: imgs_input_fn(test_files,\n",
    "                                                                   labels=test_labels,\n",
    "                                                                   perform_shuffle=True,\n",
    "                                                                   repeat_count=5,\n",
    "                                                                   batch_size=20), \n",
    "                                    max_steps=500)\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=lambda: imgs_input_fn(test_files,\n",
    "                                                                 labels=test_labels,\n",
    "                                                                 perform_shuffle=False,\n",
    "                                                                 batch_size=1))\n",
    "\n",
    "tf.estimator.train_and_evaluate(tf_estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Read about estimators and datasets in the Tensorflow Programmer's guide:\n",
    "\n",
    "- https://www.tensorflow.org/programmers_guide/estimators\n",
    "- https://www.tensorflow.org/programmers_guide/datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "copyright": true
   },
   "source": [
    "*Copyright &copy; 2017 Francesco Mosconi & CATALIT LLC. All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
