{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Learning MNIST\n",
    "\n",
    "In this exercise you will design a classifier for the very simple but very popular [MNIST dataset](http://yann.lecun.com/exdb/mnist/), a classic of dataset in computer vision and one of the first real world problems solved by neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras provides access to a few simple datasets for convenience in the `keras.datasets` module. Here we will load MNIST, a standard benchmark dataset for image classification. This will download the dataset if you have run this code before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST is a simple dataset of grayscale hand-written digits 28x28 pixels big. So there are 10 classes in the dataset corresponding to the digits 0-9. We can get a sense for what this dataset is like (always a good idea) by looking at some random samples for the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12a4c6b00>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110221630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[np.random.randint(len(X_train))], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do a little preprocessing of the dataset. Firstly, we will flatten the 28x28 images to a 784 dimensional vector. This is because our first model below does not care about the spatial dimensions, only the pixel values. The images are represented by numpy arrays of integers between 0 and 255. Since this is a fixed range, we should scale the values down to be from 0 to 1. This normalization simplifies things is usually a good idea, especially since weights are usually initialized randomly near zero.\n",
    "\n",
    "Read the code below and make sure you understand what we are doing to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "### Exercise 1 - design an MLP for MNIST\n",
    "\n",
    "Build an MLP. It is up to you what the structure of the model will be, but keep in mind that this problem is much higher dimensional than previous problems we have worked on. This is your first chance to design a model on real data! See if you can get 90% accuracy or better.\n",
    "\n",
    "Here are some of the things you will need to decide about your model:\n",
    "* number of layers\n",
    "* activation function\n",
    "* number of dimensions in each layer\n",
    "* batch size\n",
    "* number of epochs\n",
    "* learning rate\n",
    "\n",
    "Suggestions:\n",
    "* You can pass the argument `verbose=2` to the `model.fit` method to quiet the output a bit, which will speed up the training as well.\n",
    "* You already divided the training and test data, but since you will be trying a series of experiments and changing your model, it is good practice to set aside a **validation** dataset for you to use to track your model improvements. You should only use the test data after you believe you have a good model to evaluate the final performance. Keras can create a validation set for you if you pass the `validation_split=0.1` argument to `model.fit` to tell Keras to hold out 10% of the training data to use as validation.\n",
    "* You can use the `plot_loss` if you find it useful in setting your learning rate etc. during your experiments.\n",
    "* You can refer to previous notebooks and the [documentation](http://keras.io/models/sequential/).\n",
    "\n",
    "If you want to talk over design decisions, feel free to ask!\n",
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(hist):\n",
    "    loss = hist.history['loss']\n",
    "    plt.plot(range(len(loss)), loss)\n",
    "    plt.title('loss')\n",
    "    plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 1.2157 - acc: 0.7426\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3232 - acc: 0.8534\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1669 - acc: 0.9407\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0697 - acc: 0.9838\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0610 - acc: 0.9854\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0558 - acc: 0.9866\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0521 - acc: 0.9873\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0490 - acc: 0.9878\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0458 - acc: 0.9887\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0435 - acc: 0.9895\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0420 - acc: 0.9895\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0398 - acc: 0.9900\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0391 - acc: 0.9908\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0370 - acc: 0.9911\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0355 - acc: 0.9917\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0348 - acc: 0.9914\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0331 - acc: 0.9918\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0312 - acc: 0.9922\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0306 - acc: 0.9923\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0307 - acc: 0.9925\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0281 - acc: 0.9935\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0278 - acc: 0.9932\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0269 - acc: 0.9935\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0267 - acc: 0.9935\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0257 - acc: 0.9939\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0247 - acc: 0.9939\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0236 - acc: 0.9946\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0234 - acc: 0.9947\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0225 - acc: 0.9949\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0231 - acc: 0.9944\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0221 - acc: 0.9948\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0210 - acc: 0.9952\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0205 - acc: 0.9954\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0209 - acc: 0.9950\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0196 - acc: 0.9957\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0198 - acc: 0.9954\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0187 - acc: 0.9958\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0185 - acc: 0.9958\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0187 - acc: 0.9958\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0184 - acc: 0.9959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x125feb390>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.add(Dense(40, input_dim = X_train.shape[1]))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dense(20, activation='softmax'))\n",
    "#model.add(Dense(4))\n",
    "#model.add(Activation('softmax'))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "#model.fit(X_train, y_train, epochs=20, batch_size=100, verbose = 1, initial_epoch=0)\n",
    "\n",
    "model.add(Dense(40, input_dim = 784))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dense(16, activation='softmax'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=40, batch_size=200, verbose = 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.11118911837805062\n",
      "Test accuracy: 0.9673\n"
     ]
    }
   ],
   "source": [
    "# Final test evaluation\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "copyright": true
   },
   "source": [
    "*Copyright &copy; 2017 Francesco Mosconi & CATALIT LLC. All rights reserved.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
