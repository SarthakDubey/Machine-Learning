{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas morning warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "- load the `../data/titanic-train.csv` onto a variable called `df`\n",
    "- drop the 2 records missing cases on Embarked\n",
    "- create a new feature called `Fare2` that is an integer version of `Fare`\n",
    "- plot the distribution of `Fare2` using a histogram\n",
    "- create a new feature called `Fare3` that is the logarithm of `Fare` (you may have to add a small quantity to avoid log of zero)\n",
    "- plot the distribution of `Fare3` using a histogram\n",
    "- create a column called `Male` that is 1 if `Sex` is `male` and 0 otherwise\n",
    "- create dummy columns for `Pclass` and join them back to the main df\n",
    "- fill missing age data with one of these strategies\n",
    "    - fixed value\n",
    "    - mean value of age\n",
    "    - random age data based on existing age's mean and std\n",
    "- Count how many passengers paid between 10 and 50?\n",
    "- Create new categorical variable for `Fare2` with 3 buckets:\n",
    "    - Fare<=10\n",
    "    - Fare11to50\n",
    "    - Fare51+\n",
    "- convert it to dummy columns and join it to the dataframe\n",
    "- create a new feature for the presence of Family combining the information present in SibSp and in Parch. If a person has a SibSp or a Parch then he/she has a Family\n",
    "- save your final file to a local file in any format that is not csv (json, hdf5, excel, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/titanic-train.csv', index_col=None, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# drop the 2 records missing cases on Embarked\n",
    "df = df[df['Embarked'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# change fare to integer\n",
    "df['Fare2'] = df['Fare'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of Fare2 using a histogram\n",
    "df[['Fare2']].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# change fare to integer\n",
    "df['Fare3'] = np.log(df['Fare']+0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of Fare2 using a histogram\n",
    "df['Fare3'].plot(kind='hist', bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# dummy var for Gender == male {male: 1, female: 0}\n",
    "df['Male'] = 0\n",
    "df.loc[df['Sex'] == 'male', 'Male'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# create dummy columns for `Pclass` and join them back to the main df\n",
    "dum1 = pd.get_dummies(df['Pclass'], prefix='Pclass')\n",
    "df = df.join(dum1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# random age data based on existing age's mean and std\n",
    "seed = np.random.RandomState(1)\n",
    "df['Age2'] = df['Age'].apply(lambda x: seed.normal(df.Age.mean(),\n",
    "                                                   df.Age.std())\n",
    "                             if np.isnan(x) else x)\n",
    "df['Age2'] = df['Age2'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Count how many passengers paid between 10 and 50?\n",
    "df.loc[(df.Fare <= 50) & (df.Fare >= 10), 'Fare2'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Create new categorical variable for Fare2 with 3 buckets\n",
    "# - Fare<=10\n",
    "# - Fare11to50\n",
    "# - Fare51+\n",
    "# convert it to dummy columns and join it to the dataframe\n",
    "df['Fare4'] = ''\n",
    "df.loc[(df.Fare2 <= 10), 'Fare4'] = 'Fare<=10'\n",
    "df.loc[(df.Fare2 <= 50) & (df.Fare2 > 10), 'Fare4'] = 'Fare11to50'\n",
    "df.loc[(df.Fare2 > 50), 'Fare4'] = 'Fare51+'\n",
    "dum = pd.get_dummies(df['Fare4'], prefix='Fare3')\n",
    "df = df.join(dum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# create a new feature for the presence of Family combining the information\n",
    "#    present in SibSp and in Parch. If a person has a SibSp or a Parch then\n",
    "#    he/she has a Family\n",
    "df['Family'] = (df['SibSp'] > 0) | (df['Parch'] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "- reload the churn dataset (`../data/churn.csv`)\n",
    "- assign the Churn column to a variable called `y`\n",
    "- separate numerical columns like we did yesterday\n",
    "- convert the remaining categorical columns to booleans using `pd.get_dummies`\n",
    "- compare the score of a classification using only the numerical columns VS numerical + dummies (for this you'll have to do a train/test split)\n",
    "- how much do the dummies contribute to the score? Lots or little?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/churn.csv')\n",
    "y = df['Churn'] == 'Yes'\n",
    "features = df.drop('Churn', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "categorical_data = features.select_dtypes(include=['object'])\n",
    "numerical = features.select_dtypes(include=['number'])\n",
    "dummies = pd.get_dummies(categorical_data)\n",
    "all_features = pd.concat([numerical, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "Xn_train, Xn_test, Xa_train, Xa_test, y_train, y_test = \\\n",
    "    train_test_split(numerical, all_features, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "for model in [LogisticRegression(), DecisionTreeClassifier()]:\n",
    "    print(model)\n",
    "    model.fit(Xn_train, y_train)\n",
    "    sn = model.score(Xn_test, y_test)\n",
    "    model.fit(Xa_train, y_train)\n",
    "    print(\"Score on numerical: %0.2f\" % sn)\n",
    "    sa = model.score(Xa_test, y_test)\n",
    "    print(\"Score on all features: %0.2f\" % sa)\n",
    "    print(\"Percentage improvement: %0.2f %%\" % (100 * (sa-sn)/sn))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2017 CATALIT LLC.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
